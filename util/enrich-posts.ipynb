{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Posts and see if they are enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriching post Enhancing Emergency Decision-making with Knowledge Graphs and Large Language Models\n",
      "Keywords: Emergency Decision-making, Knowledge Graphs, Large Language Models, Artificial Intelligence, Evidence-based\n",
      "Summary: The academic paper entitled \"Enhancing Emergency Decision-making with Knowledge Graphs and Large Language Models\" describes the development of E-KELL, an AI-based system aimed at improving decision-making in emergency situations. The system integrates knowledge graphs and large language models, such as GPT-4-Turbo, to create a more reliable and cogent support tool for emergency responders that overcomes the limitations of previous AI systems related to hallucination and poor reasoning. E-KELL has been evaluated in real-world settings, showcasing marked enhancements in comprehensibility, accuracy, conciseness, and instructiveness based on feedback from emergency commanders and firefighters. The research suggests potential commercial applications extending from government emergency management to private sector emergency preparedness, as well as adaptations for industries handling hazardous materials and other domains requiring complex knowledge processing.\n",
      "SEO Description: AI-enhanced emergency decision-making; E-KELL integrates knowledge graphs with LLMs for reliable crisis support.\n",
      "articleSection: AI for IT; Practical AI Applications\n",
      "Post 951 enriched and saved.\n",
      "Enriching post Model-as-a-Service (MaaS): A Survey\n",
      "Keywords: Model-as-a-Service, Generative AI, Cloud computing, Deployment paradigm, Foundation models\n",
      "Summary: The academic paper \"Model-as-a-Service (MaaS): A Survey\" provides a comprehensive exploration of the MaaS concept, focusing on its role in deploying generative AI models, such as large language models, through cloud services. The authors, Wensheng Gan, Shicheng Wan, and Philip S. Yu, examine how MaaS democratizes access to advanced AI by eliminating the need for extensive infrastructure or expertise. They outline MaaS's historical development, supporting technologies, and its applications across various industries. Additionally, the paper addresses the challenges and necessary future research for MaaS, emphasizing its potential as a transformative service for AI utilization. The document also considers the commercial implications of MaaS, highlighting how it enables organizations to leverage AI without large investments and encourages innovation in AI application development and monetization.\n",
      "SEO Description: Discover MaaS: Key to easy AI model deployment and future of cloud-based AI services.\n",
      "articleSection: AI News; AI Development and Operations\n",
      "Post 948 enriched and saved.\n",
      "Enriching post PROPANE: Prompt design as an inverse problem\n",
      "Keywords: PROPANE, Prompt design, Large Language Models, semantically obfuscated prompts, optimization framework\n",
      "Summary: The academic paper \"PROPANE: Prompt design as an inverse problem\" introduces an automated optimization framework named PROPANE for prompt engineering in Large Language Models (LLMs). Developed by researchers Rimon Melamed, Lucas H. McCabe, Tanay Wakhare, Yejin Kim, H. Howie Huang, and Enric Boix-Adsera, PROPANE addresses the challenge of prompt design by formulating it as an inverse problem, aiming to reconstruct prompts that generate outputs similar to a given \"ground truth.\" The system, which minimizes the KL divergence between prompt distributions, can create \"obfuscated\" prompts that are less interpretable by humans but maintain effectiveness across different models. The paper discusses potential applications, such as reconstructing proprietary system prompts, making prompts more robust, and finding valuable prompts with intellectual property potential due to their hard-to-reverse-engineer nature._alternative prompts. Overall, PROPANE offers a new perspective on prompting LLMs and could have significant implications for benchmarking prompt engineering techniques and commercial applications in the field.\n",
      "SEO Description: Unlocking AI potential with PROPANE: Revolutionary prompt optimization for smarter, autonomous LLMs.\n",
      "articleSection: AI for IT; AI Development and Operations\n",
      "Post 945 enriched and saved.\n",
      "Enriching post Black-Box Prompt Optimization: Aligning Large Language Models without Model Training\n",
      "Keywords: Black-Box Prompt Optimization, Large Language Models, Human-AI Alignment, Prompt Engineering, Input Understanding\n",
      "Summary: The academic article discusses a new technique called Black-Box Prompt Optimization (BPO), aimed at better aligning large language models (LLMs) like GPT-3.5 and GPT-4 with user intent without retraining the models. Introduced by Jiale Cheng and colleagues, BPO optimizes the prompts fed into LLMs to enhance understanding of user instructions, proving to be an effective, model-agnostic approach. Empirical evidence shows that BPO can significantly improve the performance of these models, increasing their \"win rate\" and offering benefits over existing retraining methods like PPO and DPO. The approach is cost-effective, as it eliminates the need for expensive computational training, and makes model alignment more accessible, especially for users who cannot directly access the models for training. The authors underline the commercial viability of this method, potential applications for developers using model APIs, and provide the code and datasets for broader use in the research community.\n",
      "SEO Description: Revolutionary BPO method enhances AI alignment without retraining, boosting LLM effectiveness and user intent match.\n",
      "articleSection: AI and Machine Learning; Natural Language Processing\n",
      "Post 942 enriched and saved.\n",
      "Enriching post REINVENT4: Modern AI–Driven Generative Molecule Design\n",
      "Keywords: Generative AI, Molecule Design, Reinforcement Learning, Recurrent Neural Networks, Transformers\n",
      "Summary: REINVENT4 is an updated, open-source artificial intelligence software designed for generative applications in small molecule design. The software uses advanced machine learning techniques such as recurrent neural networks, transformer architectures, reinforcement learning, transfer learning, and curriculum learning to support various molecular design tasks like de novo design, R-group replacement, library and linker design, scaffold hopping, and molecule optimization. The platform is modular and allows for customization and integration of new components, which makes it potentially valuable for commercial drug discovery applications. REINVENT4 is freely available on GitHub under the Apache 2.0 license and includes several new features such as staged learning, a new transformer model for optimization, and support for TOML configurations, among others. Its release as open-source is envisaged to spur innovation in AI-driven molecular design by providing state-of-the-art algorithms for reference and application in computational chemistry and drug design.\n",
      "SEO Description: Discover REINVENT4: AI-powered tool revolutionizing molecule design, now open-source for drug discovery innovation.\n",
      "articleSection: AI and Analytics; AI Research and Development\n",
      "Post 935 enriched and saved.\n",
      "Enriching post How AI Fits into Lean Six Sigma\n",
      "Keywords: AI, Lean Six Sigma, Process Improvement, Generative AI, Operations Management\n",
      "Summary: The article examines the integration of artificial intelligence (AI), particularly generative AI, into Lean Six Sigma, a methodology used for process improvement in manufacturing and service operations. AI is valued for its ability to efficiently and cost-effectively execute tasks traditionally done by human experts, and is poised to enhance repetitive operational processes significantly. However, the article also acknowledges that AI won't completely supplant human involvement, creating challenges in managing the balance between technology and the workforce. The content, authored by Matthias Holweg, Thomas H. Davenport, and Ken Snyder, delves into AI’s role in operations and supply chain management, and the necessity for consulting firms and process improvement professionals to adapt to AI advancements. Moreover, it discusses the commercial prospects of AI applications in process improvement, including AI-driven software/services, the evolution of training programs, and consulting using AI capabilities. This reflects a growing trend of combining established methods like Lean Six Sigma with innovative AI applications to push the boundaries of process optimization.\n",
      "\n",
      "Keywords: AI, Lean Six Sigma, Process Improvement, Generative AI, Operations Management\n",
      "SEO Description: Explore AI's role in enhancing Lean Six Sigma for optimal process improvement in operations.\n",
      "articleSection: AI and Analytics; AI in Manufacturing and Services\n",
      "Post 931 enriched and saved.\n",
      "Post 919 already enriched, skipping.\n",
      "Post 889 already enriched, skipping.\n",
      "Post 885 already enriched, skipping.\n",
      "Post 882 already enriched, skipping.\n",
      "Post 876 already enriched, skipping.\n",
      "Post 869 already enriched, skipping.\n",
      "Post 865 already enriched, skipping.\n",
      "Post 858 already enriched, skipping.\n",
      "Post 839 already enriched, skipping.\n",
      "Post 835 already enriched, skipping.\n",
      "Post 831 already enriched, skipping.\n",
      "Post 827 already enriched, skipping.\n",
      "Post 824 already enriched, skipping.\n",
      "Post 820 already enriched, skipping.\n",
      "Post 816 already enriched, skipping.\n",
      "Post 810 already enriched, skipping.\n",
      "Post 807 already enriched, skipping.\n",
      "Post 802 already enriched, skipping.\n",
      "Post 796 already enriched, skipping.\n",
      "Post 772 already enriched, skipping.\n",
      "Post 768 already enriched, skipping.\n",
      "Post 755 already enriched, skipping.\n",
      "Post 749 already enriched, skipping.\n",
      "Post 727 already enriched, skipping.\n",
      "Post 698 already enriched, skipping.\n",
      "Post 694 already enriched, skipping.\n",
      "Post 680 already enriched, skipping.\n",
      "Post 660 already enriched, skipping.\n",
      "Post 626 already enriched, skipping.\n",
      "Post 627 already enriched, skipping.\n",
      "Post 617 already enriched, skipping.\n",
      "Post 612 already enriched, skipping.\n",
      "Post 608 already enriched, skipping.\n",
      "Post 585 already enriched, skipping.\n",
      "Post 582 already enriched, skipping.\n",
      "Post 578 already enriched, skipping.\n",
      "Post 574 already enriched, skipping.\n",
      "Post 569 already enriched, skipping.\n",
      "Post 552 already enriched, skipping.\n",
      "Post 544 already enriched, skipping.\n",
      "Post 541 already enriched, skipping.\n",
      "Post 537 already enriched, skipping.\n",
      "Post 534 already enriched, skipping.\n",
      "Post 530 already enriched, skipping.\n",
      "Post 526 already enriched, skipping.\n",
      "Post 506 already enriched, skipping.\n",
      "Post 1 already enriched, skipping.\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT ID, post_title, post_content FROM workdifferent_wp_0ksss.wmqzcV0Sj_posts WHERE post_type = 'post' AND post_status = 'publish' ORDER BY post_date desc\")\n",
    "posts = cursor.fetchall()\n",
    "for post_id, post_title, post_content in posts:\n",
    "    cursor.execute(\"SELECT * FROM workdifferent_wp_0ksss.wmqzcV0Sj_post_enrichments WHERE post_id = %s;\", (post_id,))\n",
    "    existing_summary = cursor.fetchone()\n",
    "    \n",
    "    if not existing_summary:\n",
    "        enriched_data = enrich_post(post_title, post_content)\n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO workdifferent_wp_0ksss.wmqzcV0Sj_post_enrichments (post_id, enrichment_datetime, articlesection, description, keywords, extracted_text, summary)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "        \"\"\", (post_id, datetime.now(), enriched_data['articleSection'][:80], enriched_data['description'], enriched_data['keywords'], enriched_data['extractedText'],\n",
    "              enriched_data['summary']))\n",
    "        db.commit()\n",
    "        print(f\"Post {post_id} enriched and saved.\")\n",
    "    else:\n",
    "        print(f\"Post {post_id} already enriched, skipping.\")\n",
    "cursor.close()\n",
    "db.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
