{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mysql.connector\n",
    "import openai\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "def remove_html_markup(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def truncate_text(text, max_tokens=3750):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    tokens = tokenizer.encode(text, return_tensors=\"pt\", max_length=max_tokens, truncation=True)\n",
    "    truncated_text = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "    return truncated_text\n",
    "\n",
    "def enrich_post(post_title, post_content):\n",
    "    articleSection = \"Apex, AppExchange, Approval Processes, Automated Testing, Best Practices, Case Studies, Code Reviews, Coding Standards, Continuous Deployment, Continuous Integration, Data Management, Design Patterns, Developer Community, Salesforce DevOps, Events & Webinars, Generative AI, Industry News & Updates, Industry-Specific Solutions, Infrastructure as Code, Integration, Lessons Learned, Lightning Web Components, Monitoring & Logging, New Features, Performance Optimization, Process Automation, Reports & Dashboards, Salesforce Administration, Salesforce Development, Salesforce Releases, Cybersecurity, SOQL & SOSL, Step-by-Step Guides, Success Stories, Tips & Tricks, Troubleshooting, Tutorials & How-Tos, Version Control, Visualforce, Workflow Rules\"\n",
    "    print (f\"Enriching post {post_title}\")\n",
    "    clean_content = remove_html_markup(post_content)\n",
    "    truncated_content = truncate_text(post_title+' '+clean_content)\n",
    "    \n",
    "    # Prepare the chat messages for GPT-4\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that can extract keywords, summarize text, and determine sentiment.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Extract 5 keywords in a comma-separated list without numbers from the following text: {truncated_content}\"},\n",
    "    ]\n",
    "\n",
    "    # Extract keywords\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        \n",
    "    )\n",
    "    keywords = response.choices[0].message['content'].strip()\n",
    "    print (f\"Keywords: {keywords}\")\n",
    "\n",
    "    # Create articleSection\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Pick only one 'articleSection' phrase that best describes the previous text from this comma separated list. Only repeat back the phrase exactly as listed: {articleSection}\"})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    articlesection = response.choices[0].message['content'].strip()\n",
    "    print (f\"articleSection: {articlesection}\")\n",
    "\n",
    "    # Create summary\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Write a summary of the previous text in less than 25 words or 280 characters.\"})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    summary = response.choices[0].message['content'].strip()\n",
    "    print (f\"Summary: {summary}\")\n",
    "\n",
    "    # Create SEO description\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Write an SEO-friendly summary of the previous text in less than 15 words or 160 characters\"})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    description = response.choices[0].message['content'].strip()\n",
    "    print (f\"SEO Description: {description}\")\n",
    "\n",
    "    # Determine sentiment\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Determine the sentiment of the previous text in one or two words\"})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    sentiment = response.choices[0].message['content'].strip()\n",
    "    print (f\"Sentiment: {sentiment}\")\n",
    "    result = {\n",
    "        \"articlesection\": articlesection,\n",
    "        \"description\": description,\n",
    "        \"keywords\": keywords,\n",
    "        \"extracted_text\": truncated_content,\n",
    "        \"summary\": summary,\n",
    "        \"sentiment\": sentiment,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Posts and see if they are enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up database connection\n",
    "db = mysql.connector.connect(\n",
    "    host=os.getenv(\"WORK_WP_DBMS_HOST\"),\n",
    "    user=os.getenv(\"WORK_WP_DBMS_USER\"),\n",
    "    password=os.getenv(\"WORK_WP_DBMS_PASSWORD\"),\n",
    "    database=os.getenv(\"WORK_WP_DBMS_DATABASE\")\n",
    ")\n",
    "cursor = db.cursor()\n",
    "cursor.execute(\"SELECT ID, post_title, post_content FROM wp_posts WHERE post_type = 'post' AND post_status = 'publish' ORDER BY post_date desc\")\n",
    "posts = cursor.fetchall()\n",
    "for post_id, post_title, post_content in posts:\n",
    "    cursor.execute(\"SELECT * FROM post_enrichments WHERE post_id = %s;\", (post_id,))\n",
    "    existing_summary = cursor.fetchone()\n",
    "    \n",
    "    if not existing_summary:\n",
    "        enriched_data = enrich_post(post_title, post_content)\n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO post_enrichments (post_id, enrichment_datetime, articlesection, description, keywords, extracted_text, summary, sentiment)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n",
    "        \"\"\", (post_id, datetime.now(), enriched_data['articlesection'], enriched_data['description'], enriched_data['keywords'], enriched_data['extracted_text'],\n",
    "              enriched_data['summary'], enriched_data['sentiment']))\n",
    "        db.commit()\n",
    "        print(f\"Post {post_id} enriched and saved.\")\n",
    "    else:\n",
    "        print(f\"Post {post_id} already enriched, skipping.\")\n",
    "cursor.close()\n",
    "db.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
